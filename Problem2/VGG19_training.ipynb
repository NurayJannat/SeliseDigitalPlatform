{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f3feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec77445",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991c21c",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7315aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/nur/Documents/Selise/dataset/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37cf0464",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04fc4a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nur/Documents/Selise/dataset/dataset/train\n",
      "/home/nur/Documents/Selise/dataset/dataset/test\n"
     ]
    }
   ],
   "source": [
    "print(train_dir)\n",
    "print(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c5d83",
   "metadata": {},
   "source": [
    "## Data Augmentation and Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5fef816",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255., \n",
    "    rotation_range = 40, \n",
    "    width_shift_range = 0.2, \n",
    "    height_shift_range = 0.2, \n",
    "    shear_range = 0.2, \n",
    "    zoom_range = 0.2, \n",
    "    horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac1dc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4800 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    batch_size = BATCH_SIZE, \n",
    "    class_mode = 'categorical', \n",
    "    target_size = TARGET_SIZE,\n",
    "    subset = 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce9e0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = TARGET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2c04993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_generator = test_datagen.flow_from_directory(\n",
    "#     test_dir, \n",
    "#     batch_size = BATCH_SIZE, \n",
    "#     class_mode = 'categorical', \n",
    "#     target_size = TARGET_SIZE,\n",
    "#     subset = 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143bba7",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7823bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad35df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 601s 8us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(input_shape = (224, 224, 3),\n",
    "                   include_top = False,\n",
    "                   weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "456e6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7fbbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b42e81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.SGD(lr=0.0001), loss = 'categorical_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1da2311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{acc:.2f}-{val_acc:.2f}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d18eb7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.6115 - acc: 0.2606 \n",
      "Epoch 00001: val_loss improved from inf to 1.33707, saving model to weights-improvement-01-0.26-0.34-1.34.hdf5\n",
      "50/50 [==============================] - 1596s 32s/step - loss: 1.6115 - acc: 0.2606 - val_loss: 1.3371 - val_acc: 0.3375\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.4764 - acc: 0.2969 \n",
      "Epoch 00002: val_loss improved from 1.33707 to 1.26985, saving model to weights-improvement-02-0.30-0.44-1.27.hdf5\n",
      "50/50 [==============================] - 1566s 31s/step - loss: 1.4764 - acc: 0.2969 - val_loss: 1.2698 - val_acc: 0.4381\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.4241 - acc: 0.3394 \n",
      "Epoch 00003: val_loss improved from 1.26985 to 1.21759, saving model to weights-improvement-03-0.34-0.49-1.22.hdf5\n",
      "50/50 [==============================] - 1560s 31s/step - loss: 1.4241 - acc: 0.3394 - val_loss: 1.2176 - val_acc: 0.4944\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.3528 - acc: 0.3475 \n",
      "Epoch 00004: val_loss improved from 1.21759 to 1.17180, saving model to weights-improvement-04-0.35-0.55-1.17.hdf5\n",
      "50/50 [==============================] - 1560s 31s/step - loss: 1.3528 - acc: 0.3475 - val_loss: 1.1718 - val_acc: 0.5481\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.3028 - acc: 0.3812 \n",
      "Epoch 00005: val_loss improved from 1.17180 to 1.13844, saving model to weights-improvement-05-0.38-0.57-1.14.hdf5\n",
      "50/50 [==============================] - 1566s 31s/step - loss: 1.3028 - acc: 0.3812 - val_loss: 1.1384 - val_acc: 0.5669\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.2727 - acc: 0.4056 \n",
      "Epoch 00006: val_loss improved from 1.13844 to 1.10127, saving model to weights-improvement-06-0.41-0.61-1.10.hdf5\n",
      "50/50 [==============================] - 1567s 31s/step - loss: 1.2727 - acc: 0.4056 - val_loss: 1.1013 - val_acc: 0.6106\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.2262 - acc: 0.4319 \n",
      "Epoch 00007: val_loss improved from 1.10127 to 1.07450, saving model to weights-improvement-07-0.43-0.62-1.07.hdf5\n",
      "50/50 [==============================] - 1568s 31s/step - loss: 1.2262 - acc: 0.4319 - val_loss: 1.0745 - val_acc: 0.6194\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.2057 - acc: 0.4425 \n",
      "Epoch 00008: val_loss improved from 1.07450 to 1.04501, saving model to weights-improvement-08-0.44-0.65-1.05.hdf5\n",
      "50/50 [==============================] - 1572s 31s/step - loss: 1.2057 - acc: 0.4425 - val_loss: 1.0450 - val_acc: 0.6469\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.1838 - acc: 0.4588 \n",
      "Epoch 00009: val_loss improved from 1.04501 to 1.02127, saving model to weights-improvement-09-0.46-0.68-1.02.hdf5\n",
      "50/50 [==============================] - 1565s 31s/step - loss: 1.1838 - acc: 0.4588 - val_loss: 1.0213 - val_acc: 0.6769\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.1533 - acc: 0.4913 \n",
      "Epoch 00010: val_loss improved from 1.02127 to 0.99712, saving model to weights-improvement-10-0.49-0.68-1.00.hdf5\n",
      "50/50 [==============================] - 1567s 31s/step - loss: 1.1533 - acc: 0.4913 - val_loss: 0.9971 - val_acc: 0.6831\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(train_generator, validation_data = validation_generator, steps_per_epoch = 50, epochs = 10, callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b00cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./trainHistoryDict_2nd', 'wb') as file_pi:\n",
    "    pickle.dump(vgghist.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457309eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
